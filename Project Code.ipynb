{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Competition Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uoUcOd-vaNVl",
        "dnltDTXxcEV_",
        "fTGY_OvgrwDQ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoUcOd-vaNVl",
        "colab_type": "text"
      },
      "source": [
        "## Json Data Parsing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk3rFrGyab0_",
        "colab_type": "text"
      },
      "source": [
        "Iterate through train and test json files items and save it to csv file sheet <br/>\n",
        "Permissions, Intents, APIs features and malicious data per APK\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxubJkMwaDrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import libraries\n",
        "import ijson\n",
        "import csv\n",
        "import pandas as pd \n",
        "from ast import literal_eval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys8onju1bfhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"train.json\"\n",
        "with open(filename, 'r',encoding='UTF-8') as fd,  open('TrainData.csv', mode='w',encoding='UTF-8', newline='') as out:\n",
        "    fieldnames = ['Malicious, Permissions, Intents, Apis']\n",
        "    writer = csv.writer(out, delimiter=',')\n",
        "    writer.writerow(fieldnames)\n",
        "    for item in ijson.items(fd, \"data.item\"):\n",
        "        Notempty=bool(item)\n",
        "        if Notempty: \n",
        "            writer.writerow([str(item[\"Malicious\"]),,str(item[\"Permissions\"]),str(item[\"Intents\"]),item[\"Apis\"]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEIoBFGybdk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"test.json\"\n",
        "with open(filename, 'r',encoding='UTF-8') as fd,  open('TestData.csv', mode='w',encoding='UTF-8', newline='') as out:\n",
        "    fieldnames = ['Permissions, Intents, Apis']\n",
        "    writer = csv.writer(out, delimiter=',')\n",
        "    writer.writerow(fieldnames)\n",
        "    for item in ijson.items(fd, \"data.item\"):\n",
        "        Notempty=bool(item)\n",
        "        if Notempty: \n",
        "            writer.writerow([str(item[\"Permissions\"]),str(item[\"Intents\"]),item[\"Apis\"]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnltDTXxcEV_",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnHwyYQWdP2b",
        "colab_type": "text"
      },
      "source": [
        "We have used only android Permissions, android Intents and extract android api from up to 50 APIs per APK. <br/>\n",
        "When extracting android permissions and intents features alone we got 0.2 loss, however extracting APIs features from maximum 50 API per APK with feature selection improves the loss to 0.14. <br/>\n",
        "**Note:** The APIs data processing needs 2-3 days to fill out the matrix of features per APK."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4W_IuRfesY2",
        "colab_type": "text"
      },
      "source": [
        "1. Permissions Features: Train Data contains 354 android permissions and Test Data contains 349 android permissions. <br/>\n",
        "We took the intersection of these features: 272 android permissions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtQHn7kJgIRI",
        "colab_type": "text"
      },
      "source": [
        "*  **Train Permissions Fearures**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49znxGQRcJvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv('TrainData.csv',encoding='ISO-8859-1')\n",
        "permissions=pd.DataFrame(data[\"Permissions\"])\n",
        "#convert to literal from string\n",
        "for i , row in permissions.iterrows():\n",
        "    permissions.at[i,'Permissions']=literal_eval((permissions.at[i,'Permissions']))\n",
        "#extract only android.permission\n",
        "PermissionsList=set()#set to get unique android permissions\n",
        "for i , row in permissions.iterrows():\n",
        "    pdata= permissions.at[i,'Permissions']\n",
        "    for item in pdata:\n",
        "        if item!=\"\":\n",
        "              if item.startswith(\"android.permission.\"):\n",
        "                    item=item.split(\"android.permission.\",1)[1]\n",
        "                    #print(item)\n",
        "                    if \"maxSdkVersion\" in item: #clean permissions that contain maxSdkVersion\n",
        "                        item=item.split(\"' maxSdkVersion\",1)[0]\n",
        "                        PermissionsList.add(item.upper())\n",
        "                    else: \n",
        "                        PermissionsList.add(item.upper())    \n",
        "print(len(PermissionsList))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnnXgVE6gPUw",
        "colab_type": "text"
      },
      "source": [
        "* **Test Permissions Features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3TDrkJNe55H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testdata=pd.read_csv('TestData.csv',encoding='ISO-8859-1')\n",
        "testpermissions=pd.DataFrame(testdata[\"Permissions\"])\n",
        "#covert to literal from string\n",
        "for i , row in testpermissions.iterrows():\n",
        "    testpermissions.at[i,'Permissions']=literal_eval((testpermissions.at[i,'Permissions']))  \n",
        "testPermissionList=set()\n",
        "for i , row in testpermissions.iterrows():\n",
        "    pdata= testpermissions.at[i,'Permissions']\n",
        "    for item in pdata:\n",
        "        if item!=\"\":\n",
        "              if item.startswith(\"android.permission.\"):\n",
        "                    item=item.split(\"android.permission.\",1)[1]\n",
        "                    #print(item)\n",
        "                    if \"maxSdkVersion\" in item:\n",
        "                        item=item.split(\"' maxSdkVersion\",1)[0]\n",
        "                        testPermissionList.add(item.upper())\n",
        "                    else:\n",
        "                        testPermissionList.add(item.upper())                                     \n",
        "print(len(testPermissionList))              \n",
        "              "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj7CdC2GgSqG",
        "colab_type": "text"
      },
      "source": [
        "* **Intersection of Test and Train Permissions Features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UTDN7cyf43F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IntersectPermissions= PermissionsList.intersection(testPermissionList)\n",
        "FinalPermissions=[]\n",
        "for i in IntersectPermissions: \n",
        "    FinalPermissions.append(i)\n",
        "FinalPermissions = list(filter(None, FinalPermissions))\n",
        "FinalPermissions=sorted(FinalPermissions)\n",
        "print(len(FinalPermissions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbGgqeiogZ3P",
        "colab_type": "text"
      },
      "source": [
        "* **Train Permissions Matrix** <br/>\n",
        "If feature found set to 1 else to 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzFSVarngF3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BinaryPermissions=pd.DataFrame(columns=FinalPermissions)\n",
        "for i , row in permissions.iterrows():\n",
        "    pdatabinary= permissions.at[i,'Permissions'] \n",
        "    BinaryPermissions.loc[i]=0\n",
        "    print(i)\n",
        "    for item in pdatabinary:\n",
        "        if item!=\"\":\n",
        "            if item.startswith(\"android.permission.\"):\n",
        "                item=item.split(\"android.permission.\",1)[1]\n",
        "                if \"maxSdkVersion\" in item:\n",
        "                    item=item.split(\"' maxSdkVersion\",1)[0]\n",
        "                it=item.upper()\n",
        "                if(it in FinalPermissions):\n",
        "                    BinaryPermissions.loc[i,it]=1               \n",
        "BinaryPermissions.fillna(0, inplace=True)                \n",
        "BinaryPermissions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e10gZXngi7cV",
        "colab_type": "text"
      },
      "source": [
        "* **Test Permissions Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJjdvsFjjIa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testBinaryPermissions=pd.DataFrame(columns=FinalPermissions)\n",
        "for i , row in testpermissions.iterrows():\n",
        "    print(i)\n",
        "    tpdatabinary= testpermissions.at[i,'Permissions']  \n",
        "    testBinaryPermissions.loc[i]=0\n",
        "    for item in tpdatabinary:\n",
        "        if item!=\"\":\n",
        "             if item.startswith(\"android.permission.\"):\n",
        "               item=item.split(\"android.permission.\",1)[1]\n",
        "               if \"maxSdkVersion\" in item:\n",
        "                 item=item.split(\"' maxSdkVersion\",1)[0]\n",
        "               it=item.upper()\n",
        "               if(it in FinalPermissions):\n",
        "                 testBinaryPermissions.loc[i,it]=1\n",
        "testBinaryPermissions.fillna(0, inplace=True)               \n",
        "testBinaryPermissions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7r8psjVji7u",
        "colab_type": "text"
      },
      "source": [
        "2. Intent Features: Train Data contains 682 android Intents and Test data contains 409 android Intents <br/>\n",
        "We took the intersection of these features: 203 android Intents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTlBPUWmj7Mn",
        "colab_type": "text"
      },
      "source": [
        "* **Train Intents Features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9AhynGYju1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv('TrainData.csv',encoding='ISO-8859-1')\n",
        "intents=pd.DataFrame(data[\"Intents\"])\n",
        "for i , row in intents.iterrows():\n",
        "    intents.at[i,'Intents']=literal_eval(intents.at[i,'Intents'])\n",
        "IntentsList=set()#unique android intents\n",
        "for i , row in intents.iterrows():\n",
        "    pdata= intents.at[i,'Intents']\n",
        "    for item in pdata:\n",
        "        if item!=\"\":\n",
        "              if item.startswith(\"android.intent.\"):\n",
        "                item=item.split(\"android.intent.\",1)[1]\n",
        "                IntentsList.add(item.upper())\n",
        "print(len(IntentsList))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go5eWhcwkFB_",
        "colab_type": "text"
      },
      "source": [
        "* **Test Intents Features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naHfazKjkDi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testdata=pd.read_csv('TestData.csv',encoding='ISO-8859-1')\n",
        "testintents=pd.DataFrame(testdata[\"Intents\"])\n",
        "for i , row in testintents.iterrows():\n",
        "    testintents.at[i,'Intents']=literal_eval(testintents.at[i,'Intents'])   \n",
        "testIntentsList=set()#unique android Intents\n",
        "for i , row in testintents.iterrows():\n",
        "    pdata= testintents.at[i,'Intents']\n",
        "    for item in pdata:\n",
        "        if item!=\"\":\n",
        "              if item.startswith(\"android.intent.\"):\n",
        "                item=item.split(\"android.intent.\",1)[1]\n",
        "                testIntentsList.add(item.upper())\n",
        "print(len(testIntentsList))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiSIAgMGkO_z",
        "colab_type": "text"
      },
      "source": [
        "* **Intersection of Train and Test Intentions Features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMzClmRNlMgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IntersectIntents= IntentsList.intersection(testIntentsList)\n",
        "FinalIntents=[]\n",
        "for i in IntersectIntents: \n",
        "    FinalIntents.append(i)\n",
        "FinalIntents = list(filter(None, FinalIntents))\n",
        "FinalIntents=sorted(FinalIntents)\n",
        "print(len(FinalIntents))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iad7HqgMlOhZ",
        "colab_type": "text"
      },
      "source": [
        "* **Train Intents Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bylJmsvcll79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BinaryIntents=pd.DataFrame(columns=FinalIntents)\n",
        "for i , row in intents.iterrows():\n",
        "    idatabinary= intents.at[i,'Intents']\n",
        "    BinaryIntents.loc[i]=0\n",
        "    for item in idatabinary:\n",
        "        if item!=\"\":\n",
        "            if item.startswith(\"android.intent.\"):\n",
        "                it=item.upper()\n",
        "                if((it.split(\"ANDROID.INTENT.\",1)[1]) in FinalIntents):\n",
        "                    BinaryIntents.loc[i,it.split(\"ANDROID.INTENT.\",1)[1]]=1\n",
        "BinaryIntents.fillna(0, inplace=True)                \n",
        "BinaryIntents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9HT53axltBT",
        "colab_type": "text"
      },
      "source": [
        "* **Test Intents Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1FQ23dQlyPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testBinaryIntents=pd.DataFrame(columns=FinalIntents)\n",
        "for i , row in testintents.iterrows():\n",
        "    tidatabinary= testintents.at[i,'Intents']\n",
        "    testBinaryIntents.loc[i]=0\n",
        "    for item in tidatabinary:\n",
        "        if item!=\"\":\n",
        "            if item.startswith(\"android.intent.\"):\n",
        "                it=item.upper()\n",
        "                if((it.split(\"ANDROID.INTENT.\",1)[1]) in FinalIntents):\n",
        "                    testBinaryIntents.loc[i,it.split(\"ANDROID.INTENT.\",1)[1]]=1\n",
        "\n",
        "testBinaryIntents.fillna(0, inplace=True)\n",
        "testBinaryIntents.to_csv(\"IntentsTrainingData.csv\")                       \n",
        "testBinaryIntents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK6wuFOHmRGi",
        "colab_type": "text"
      },
      "source": [
        "3. APIs Features: Train data contains 149112 android APIs and Test data contains 127012 android APIs <br/>\n",
        "The intersection of these features: 84041 android APIs. <br/> \n",
        "84041 is a very huge number of features, so we have decided to extract android APIs features from 50 APIs  per APK. <br/>\n",
        "Taking max of 50 API per APK we have the data as follows: train data 4191 android APIs , test data 3352 android APIs and the intersection 2691"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVrN28Jkopi0",
        "colab_type": "text"
      },
      "source": [
        "* **Train APIs features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzDtRfCll-3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv('TrainData.csv',encoding='ISO-8859-1')\n",
        "apis=pd.DataFrame(data[\"Apis\"])\n",
        "for i , row in apis.iterrows():\n",
        "    apis.at[i,'Apis']=literal_eval((apis.at[i,'Apis']))\n",
        "ApisList=set()#unique android apis up to 50 apis\n",
        "c=0\n",
        "for i , row in apis.iterrows():\n",
        "    pdata= apis.at[i,'Apis']\n",
        "    print(i)\n",
        "    for item in pdata:\n",
        "        if item!=\" \":\n",
        "            if(len(item)>2):\n",
        "                c+=1\n",
        "                item=item.split(\" \",1)[1]\n",
        "            if item.startswith(\"android.\"):\n",
        "                ApisList.add(item.upper())\n",
        "            if c==50:\n",
        "                c=0\n",
        "                break\n",
        "print(len(ApisList))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp6VnamnrOBo",
        "colab_type": "text"
      },
      "source": [
        " * **Test APIs Features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUYZN9RTo0I0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testdata=pd.read_csv('TestApis.csv',encoding='ISO-8859-1')\n",
        "testapis=pd.DataFrame(testdata[\"Apis\"])\n",
        "for i , row in testapis.iterrows():\n",
        "    testapis.at[i,'Apis']=literal_eval((testapis.at[i,'Apis']))\n",
        "TestApisList=set()#unique android apis up to 50 apis\n",
        "c=0\n",
        "for i , row in testapis.iterrows():\n",
        "    pdata= testapis.at[i,'Apis']\n",
        "    print(i)\n",
        "    for item in pdata:\n",
        "        if item!=\" \":\n",
        "            if(len(item)>2):\n",
        "                c+=1\n",
        "                item=item.split(\" \",1)[1]\n",
        "            if item.startswith(\"android.\"):\n",
        "                TestApisList.add(item.upper())              \n",
        "            if c==50:\n",
        "                c=0\n",
        "                break            \n",
        "        \n",
        "print(len(TestApisList))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCBvQKvWrWk-",
        "colab_type": "text"
      },
      "source": [
        "* **Intersection of Test and Train APIs Features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVNaeEWxp-IQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IntersectApis= ApisList.intersection(TestApisList)\n",
        "FinalApis=[]\n",
        "for i in IntersectApis: \n",
        "    FinalApis.append(i)\n",
        "FinalApis = list(filter(None, FinalApis))\n",
        "FinalApis=sorted(FinalApis)\n",
        "print(len(FinalApis))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM_UZ4w8rcMe",
        "colab_type": "text"
      },
      "source": [
        "* **Train APIs Matrix** <br/> This may take up to 40 hours to finish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kflV6-YqCX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BinaryApis=pd.DataFrame(columns=FinalApis)\n",
        "c=0\n",
        "#fill the matrix with 0 values to take all rows\n",
        "for i , row in apis.iterrows():\n",
        "    pdatabinary= apis.at[i,'Apis']  \n",
        "    BinaryApis.loc[i]=0\n",
        "#iterate through features if found 1 else 0\n",
        "for i,row in apis.iterrows():\n",
        "    pdatabinary= apis.at[i,'Apis'] \n",
        "    for item in pdatabinary:\n",
        "        if (len(item)>2):\n",
        "            if(item.split(\" \",1)[1].startswith(\"android.\")):\n",
        "                item=item.upper()\n",
        "                c+=1\n",
        "                if (item.split(\" \",1)[1] in FinalApis):\n",
        "                    BinaryApis.loc[i,item.split(\" \",1)[1]]=1\n",
        "            if c==50:\n",
        "                c=0\n",
        "                break\n",
        "    print(i)\n",
        "BinaryApis.fillna(0, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ4Djsf_rlXW",
        "colab_type": "text"
      },
      "source": [
        "* **Test APIs Matrix** <br/> This may take up to 25 hours to finish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSr3F-qVqaHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TestBinaryApis=pd.DataFrame(columns=FinalApis)\n",
        "c=0\n",
        "#fill the matrix with 0 values to take all rows\n",
        "for i , row in testapis.iterrows():\n",
        "    pdatabinary= testapis.at[i,'Apis']  \n",
        "    TestBinaryApis.loc[i]=0\n",
        "#iterate through features if found 1 else 0\n",
        "for i,row in testapis.iterrows():\n",
        "    pdatabinary= testapis.at[i,'Apis'] \n",
        "    d+=1\n",
        "    for item in pdatabinary:\n",
        "        if (len(item)>2):\n",
        "            if(item.split(\" \",1)[1].startswith(\"android.\")):\n",
        "                item=item.upper()\n",
        "                c+=1\n",
        "                if (item.split(\" \",1)[1] in FinalApis):\n",
        "                    TestBinaryApis.loc[i,item.split(\" \",1)[1]]=1\n",
        "            if c==50:\n",
        "                c=0\n",
        "                break\n",
        "    print(i)\n",
        "TestBinaryApis.fillna(0, inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTGY_OvgrwDQ",
        "colab_type": "text"
      },
      "source": [
        "# Combining Data and Classification Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sof-KuKvRdL",
        "colab_type": "text"
      },
      "source": [
        "Final number of features 1 ID column+272 permissions+203 Intents+2691 APIs = 3167 features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5Rw782lsyTd",
        "colab_type": "text"
      },
      "source": [
        "* **XTrain File combine all train matrix files and save it to csv file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BcBEEAAr8eB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BinaryPermissions.index.name=\"ID\"\n",
        "BinaryIntents.index.name=\"ID\"\n",
        "BinaryPerIntents= BinaryPermissions.merge(BinaryIntents, on=\"ID\")\n",
        "BinaryApis.index.name=\"ID\"\n",
        "Xtrain=BinaryPerIntents.merge(BinaryApis, on=\"ID\")\n",
        "Xtrain.to_csv(\"Xtrain.csv\") \n",
        "Xtrain"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZjUJ8fqt5OX",
        "colab_type": "text"
      },
      "source": [
        "* **Ytrain File is the malicious field set False to 0 and True to 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71AxaBR0uEFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "malicious=pd.DataFrame(data[\"Malicious\"])\n",
        "for i , row in malicious.iterrows():\n",
        "    item=malicious.at[i,\"Malicious\"]\n",
        "    if(str(item)==\"True\"):\n",
        "        malicious.loc[i,\"Malicious\"]=1\n",
        "    else:\n",
        "        malicious.loc[i,\"Malicious\"]=0\n",
        "malicious.index.name=\"ID\"\n",
        "malicious.to_csv(\"Ytrain.csv\") \n",
        "malicious"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhwwYpZStJaO",
        "colab_type": "text"
      },
      "source": [
        "* **XTest File combine all test matrix files and save it to csv file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTjsWMwos3s2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testBinaryPermissions.index.name=\"ID\"\n",
        "testBinaryIntents.index.name=\"ID\"\n",
        "TestBinaryPerIntents=testBinaryPermissions.merge(testBinaryIntents, on=\"ID\")\n",
        "TestBinaryApis.index.name=\"ID\"\n",
        "Xtest=TestBinaryPerIntents.merge(TestBinaryApis, on=\"ID\")\n",
        "Xtest.to_csv(\"Xtest.csv\") \n",
        "Xtest"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl771tRe6Lsy",
        "colab_type": "text"
      },
      "source": [
        "## Feature Selection and Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd3jwf3IuwoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd \n",
        "import csv \n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler,MaxAbsScaler,QuantileTransformer,Normalizer,PowerTransformer,RobustScaler\n",
        "\n",
        "X= pd.read_csv(\"Xtrain.csv\")\n",
        "Y= pd.read_csv(\"Ytrain.csv\")\n",
        "Y=pd.DataFrame(Y[\"Malicious\"])\n",
        "print(X.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jsZc_NCwAVo",
        "colab_type": "text"
      },
      "source": [
        "* Split the train data to X_train, X_test and y_train,y_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4f5kU6gv-1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqql4zvfwTc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,QuantileTransformer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "model = SelectFromModel(estimator=LogisticRegression(solver='liblinear',penalty=\"l1\"),threshold= 0.001).fit(X_train, y_train)\n",
        "X_train_new = model.transform(X_train)\n",
        "X_test_new = model.transform(X_test)\n",
        "selcted_features = X_train.columns[model.get_support()]\n",
        "print(X_train_new.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcaGGA6DwWW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Selected features\n",
        "selcted_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GhIrFXdweeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = LogisticRegression(solver='liblinear',penalty=\"l1\")\n",
        "clf.fit(X_train[selcted_features], y_train)\n",
        "print(\"Feature Selection Training accuracy:\", clf.score(X_train[selcted_features], y_train))\n",
        "print(\"Feature Selection Test accuracy:\",clf.score(X_test[selcted_features],y_test))\n",
        "diff_base = abs(clf.score(X_train[selcted_features], y_train) - clf.score(X_test[selcted_features],y_test))\n",
        "print(\"Over / under fitting of the model：\", diff_base)\n",
        "pred_test = clf.predict(X_test[selcted_features])\n",
        "print(\"Loss\", log_loss(y_test, pred_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyM0VF7gwvzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_data= pd.read_csv(\"Xtest.csv\")\n",
        "print(X_test_data.shape)\n",
        "y_test_pred = clf.predict_proba(X_test_data[selcted_features])\n",
        "results=pd.DataFrame(y_test_pred)\n",
        "results.to_csv(\"Predictions.csv\")   \n",
        "results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EeJ_fYU6fly",
        "colab_type": "text"
      },
      "source": [
        "## Scaler and Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVunB5db2fU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd \n",
        "import csv \n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler,MaxAbsScaler,QuantileTransformer,Normalizer,PowerTransformer,RobustScaler\n",
        "\n",
        "X= pd.read_csv(\"Xtrain.csv\")\n",
        "Y= pd.read_csv(\"Ytrain.csv\")\n",
        "Y=pd.DataFrame(Y[\"Malicious\"])\n",
        "print(X.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQDacCWZ2iLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1GGhueRx4fC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,QuantileTransformer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Fit to data and predict using pipelined LogisticRegression and PCA.\n",
        "unscaled_clf = make_pipeline(PCA(n_components=900), LogisticRegression(solver='liblinear',penalty=\"l1\"))\n",
        "unscaled_clf.fit(X_train, y_train)\n",
        "pred_test = unscaled_clf.predict(X_test)\n",
        "print(unscaled_clf.score(X_train, y_train))\n",
        "\n",
        "# Fit to data and predict using pipelined scaling, LogisticRegression and PCA.\n",
        "std_clf = make_pipeline( StandardScaler(), PCA(n_components=900), LogisticRegression(solver='liblinear',penalty=\"l1\"))\n",
        "std_clf.fit(X_train, y_train)\n",
        "pred_test_std = std_clf.predict(X_test)\n",
        "print(std_clf.score(X_train, y_train))\n",
        "\n",
        "# Fit to data and predict using pipelined scaling, LogisticRegression and PCA.\n",
        "qt_clf = make_pipeline(QuantileTransformer(), PCA(n_components=900), LogisticRegression(solver='liblinear',penalty=\"l1\"))\n",
        "qt_clf.fit(X_train, y_train)\n",
        "print(qt_clf.score(X_train, y_train))\n",
        "pred_test_qt = qt_clf.predict(X_test)\n",
        "\n",
        "# Fit to data and predict using pipelined scaling, LogisticRegression and PCA.\n",
        "mm_clf = make_pipeline(MinMaxScaler(), PCA(n_components=900), LogisticRegression(solver='liblinear',penalty=\"l1\"))\n",
        "mm_clf.fit(X_train, y_train)\n",
        "pred_test_mm = mm_clf.predict(X_test)\n",
        "print(mm_clf.score(X_train, y_train))\n",
        "\n",
        "# Fit to data and predict using pipelined scaling, LogisticRegression and PCA.\n",
        "rs_clf = make_pipeline(RobustScaler(), PCA(n_components=900), LogisticRegression(solver='liblinear',penalty=\"l1\"))\n",
        "rs_clf.fit(X_train, y_train)\n",
        "print(rs_clf.score(X_train, y_train))\n",
        "pred_test_rs= rs_clf.predict(X_test)\n",
        "\n",
        "# Show prediction accuracies in scaled and unscaled data and log loss\n",
        "print('\\nPrediction accuracy for the normal test dataset with PCA')\n",
        "print('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test)))\n",
        "print(log_loss(y_test, pred_test))\n",
        "\n",
        "print('\\nPrediction accuracy for the standardized test dataset with PCA')\n",
        "print('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test_std)))\n",
        "print(log_loss(y_test, pred_test_std))\n",
        "\n",
        "\n",
        "print('\\nPrediction accuracy for the QuantileTransformer test dataset with PCA')\n",
        "print('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test_qt)))\n",
        "print(log_loss(y_test, pred_test_qt))\n",
        "\n",
        "\n",
        "print('\\nPrediction accuracy for the minmax test dataset with PCA')\n",
        "print('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test_mm)))\n",
        "print(log_loss(y_test, pred_test_mm))\n",
        "\n",
        "\n",
        "print('\\nPrediction accuracy for the robust scaler test dataset with PCA')\n",
        "print('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test_rs)))\n",
        "print(log_loss(y_test, pred_test_rs))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6r2WOyT3Czg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_data= pd.read_csv(\"Xtest.csv\")\n",
        "print(X_test_data.shape)\n",
        "#y_test_pred = unscaled_clf.predict_proba(X_test_data)\n",
        "#y_test_pred = std_clf.predict_proba(X_test_data)\n",
        "y_test_pred = qt_clf.predict_proba(X_test_data)\n",
        "#y_test_pred = mm_clf.predict_proba(X_test_data)\n",
        "#y_test_pred = rs_clf.predict_proba(X_test_data)\n",
        "results=pd.DataFrame(y_test_pred)\n",
        "results.to_csv(\"Predictions.csv\")   \n",
        "results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9ZWDccR6jva",
        "colab_type": "text"
      },
      "source": [
        "## Scaler and Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml-229OX6zcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd \n",
        "import csv \n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler,MaxAbsScaler,QuantileTransformer,Normalizer,PowerTransformer,RobustScaler\n",
        "\n",
        "X= pd.read_csv(\"Xtrain.csv\")\n",
        "Y= pd.read_csv(\"Ytrain.csv\")\n",
        "Y=pd.DataFrame(Y[\"Malicious\"])\n",
        "#X = StandardScaler().fit_transform(X)\n",
        "#X = MinMaxScaler().fit_transform(X)\n",
        "X = QuantileTransformer().fit_transform(X) #was the best\n",
        "print(X.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DprFkwxBxVlt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X= pd.read_csv(\"Xtrain.csv\")\n",
        "Y= pd.read_csv(\"Ytrain.csv\")\n",
        "Y=pd.DataFrame(Y[\"Malicious\"])\n",
        "X = QuantileTransformer().fit_transform(X)\n",
        "print(X.shape)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM2tkdXzxCsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "# mlp for regression with mse loss function\n",
        "from sklearn.datasets import make_regression\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD,Adagrad,Adam\n",
        "from matplotlib import pyplot\n",
        "import tensorflow_probability as tfp\n",
        "from keras.regularizers import l1\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(92, input_dim=3167, activation='sigmoid'))\n",
        "model.add(Dense(92, activation='sigmoid'))\n",
        "model.add(Dense(92, activation='sigmoid'))\n",
        "model.add(Dense(92, activation='sigmoid'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "opt = SGD(lr=0.04,clipnorm=1)\n",
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "# fit model\n",
        "history = model.fit(X_train, y_train, epochs=100,verbose=1,validation_data=(X_test, y_test))\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test,verbose=1)\n",
        "y_predict = model.predict(X_test)\n",
        "print (y_predict[0:5])\n",
        "print (y_test[0:5])\n",
        "print('Test accuracy:', test_acc)\n",
        "import matplotlib.pyplot as plt\n",
        "print (history.history.keys())\n",
        "fig = plt.figure() \n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['loss'], loc='upper left')\n",
        "plt.show()\n",
        "fig = plt.figure() \n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['loss'], loc='upper left')\n",
        "plt.show()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDfVbajoxnJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "X_test_data= pd.read_csv(\"Xtest.csv\")\n",
        "X_test_data = QuantileTransformer().fit_transform(X_test_data)\n",
        "y_test_pred=clf.predict(X_test_data)\n",
        "results=pd.dataframe(y_test_pred)\n",
        "results"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}